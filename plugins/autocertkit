#!/usr/bin/env python3

# Copyright (c) 2005-2022 Citrix Systems Inc.
# Copyright (c) 2023 Cloud Software Group, Inc.
#
# Redistribution and use in source and binary forms,
# with or without modification, are permitted provided
# that the following conditions are met:
#
# *   Redistributions of source code must retain the above
#     copyright notice, this list of conditions and the
#     following disclaimer.
# *   Redistributions in binary form must reproduce the above
#     copyright notice, this list of conditions and the
#     following disclaimer in the documentation and/or other
#     materials provided with the distribution.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND
# CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
# INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR
# CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
# BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
# WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
# NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
# SUCH DAMAGE.

#
# XenAPI plugin for retrieving XenStore data about a VM Guest
#

import XenAPI
import XenAPIPlugin
import subprocess
import os
import sys
import shutil
import time
import re
import tarfile
import datetime
import json
sys.path.append("/opt/xensource/packages/files/auto-cert-kit")
import hwinfo.tools.inspector as inspector
import binascii
import uuid

sys.path.append("/opt/xensource/packages/files/auto-cert-kit/pypackages")
from acktools.net import route
import acktools.log

# The biosdevname library has been moved in Tamapa,
# so we must ensure that we check that we cope with
# previous versions of XS, which use xcp.biosdevname.

try:
    from xcp.net.biosdevname import *
except ImportError:
    from xcp.biosdevname import *

from xcp.pci import *

INSTALL_DIR = '/opt/xensource/packages/files/auto-cert-kit'

if INSTALL_DIR not in sys.path:
    sys.path.insert(0, INSTALL_DIR)
from common import *


XE = '/opt/xensource/bin/xe'

PS = "/bin/ps"
KILL = "/bin/kill"
UNAME = "/bin/uname"
SYSCTL = "/sbin/sysctl"

CAT = "/bin/cat"
PGREP = "/usr/bin/pgrep"

IP = "/sbin/ip"
IFCONFIG = "/sbin/ifconfig"
ARPING = "/sbin/arping"
ROUTE = "/sbin/route"
ETHTOOL = "/sbin/ethtool"
DHCLIENT = "/sbin/dhclient"

SSH = "/usr/bin/ssh"
IPERF = "/usr/bin/iperf"
LMBENCH = "/usr/bin/lmbench"
TCPDUMP = "/usr/sbin/tcpdump"

FOR_CLEANUP = "for_cleanup"

XS_INVENTORY_PATH = "/etc/xensource-inventory"
LMBENCH_RESULTS_DIR = '%s/lmbench_results' % INSTALL_DIR
LMBENCH_CONF_LOC = "%s/config/lmbench.conf" % INSTALL_DIR
LOGROTATE_CONF_LOC = "%s/config/logrotate.conf" % INSTALL_DIR

LOG_NAME = "auto-cert-kit-plugin"
LOG_LOC = '/var/log/auto-cert-kit-plugin.log'

SSH_PUBLIC_KEY = '/root/.ssh/id_rsa.pub'
SSH_HOST_KEYS = '/root/.ssh/known_hosts'

IPERF_RPM = "iperf-2.0.10-1.el7.x86_64.rpm"
LMBENCH_RPM = "lmbench-3.0-0.a7.1.el7.rf.x86_64.rpm"
IOZONE_RPM = "iozone-3.471-1.el7.x86_64.rpm"
BONNIE_RPM = "bonnie++-1.96-1.el7.rf.x86_64.rpm"
TCPDUMP_RPM = "tcpdump-4.9.3-3.el8.x86_64.rpm"

OFFLOAD_CODES = {'udp-fragmentation-offload': 'ufo',
                 'scatter-gather': 'sg',
                 'generic-segmentation-offload': 'gso',
                 'tx-checksumming': 'tx',
                 'large-receive-offload': 'lro',
                 'generic-receive-offload': 'gro',
                 'tcp-segmentation-offload': 'tso',
                 'rx-checksumming': 'rx',
                 'rx-vlan-offload': 'rxvlan',
                 'tx-vlan-offload': 'txvlan',
                 'ntuple-filters': 'ntuple',
                 'receive-hashing': 'rxhash'}

OFFLOAD_FLAGS_OFFSET = {'sg': 1,
                        'tso': 1 << 16,
                        'ufo': 1 << 17,
                        'gso': 1 << 11,
                        'gro': 1 << 14,
                        'lro': 1 << 15,
                        'rxvlan': 1 << 8,
                        'txvlan': 1 << 7,
                        'ntuple': 1 << 27,
                        'rxhash': 1 << 28}

XCP_MIN_VER_WITH_SRIOV = "2.6.0"


# Logging setup
def configure_logging():
    global log
    log = acktools.log.configure_log(LOG_NAME, LOG_LOC, False)


configure_logging()
set_logger(log)

def release_logging():
    global log
    if log:
        acktools.log.release_log(log)

# Exceptions


class PluginError(Exception):
    """Base Exception class for all plugin errors."""

    def __init__(self, *args):
        Exception.__init__(self, *args)


class ArgumentError(PluginError):
    """Raised when required arguments are missing, argument values are invalid,
    or incompatible arguments are given.
    """

    def __init__(self, *args):
        PluginError.__init__(self, *args)

# Exception Decorator


def log_exceptions(func):
    def decorated(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except XenAPI.Failure as e:
            log.error('%s: XenAPI.Failure: %s', func.__name__, str(e))
            raise
        except PluginError as e:
            log.error('%s: %s: %s', func.__name__,
                      e.__class__.__name__, str(e))
            raise
        except Exception as e:
            log.error('%s: %s: %s', func.__name__,
                      e.__class__.__name__, str(e))
            raise
    return decorated
#############################


class Iface(object):
    """Class representing an ethernet interface"""

    required_keys = ["ip", "mask", "mac"]

    def __init__(self, rec):
        self.validate_rec(rec)

        for k, v in rec.items():
            setattr(self, k, v)

    def validate_rec(self, rec):
        for key in self.required_keys:
            if key not in rec.keys():
                raise Exception("Error: invalid input rec '%s'" % rec)

    def to_rec(self):
        rec = {}
        for key in self.required_keys:
            rec[key] = getattr(self, key)
        return rec


# Argument validation

ARGUMENT_PATTERN = re.compile(r'^[a-zA-Z0-9_:\.\-,]+$')
# Base64 allows the '=' symbol for padding - which is disallowed in shell-safe regex
# Extra symbols: '=', '/', '+'
ARGUMENT_PATTERN_BASE64 = re.compile(r'^[a-zA-Z0-9_:\.\-\=\/\+,]+$')


def validate_exists(args, key, default=None, required=True):
    """Validates that a string argument to a RPC method call is given, and
    matches the shell-safe regex, with an optional default value in case it
    does not exist.

    Returns the string.
    """
    if key in args:
        if len(args[key]) == 0:
            raise ArgumentError(
                'Argument %r value %r is too short.' % (key, args[key]))
        if key == "vhd_blocks":
            if not ARGUMENT_PATTERN_BASE64.match(args[key]):
                raise ArgumentError(
                    'Argument %r value %r contains invalid characters for Base64.' % (key, args[key]))
        elif not ARGUMENT_PATTERN.match(args[key]):
            raise ArgumentError(
                'Argument %r value %r contains invalid characters.' % (key, args[key]))
        if args[key][0] == '-':
            raise ArgumentError(
                'Argument %r value %r starts with a hyphen.' % (key, args[key]))
        return args[key]
    elif not required or not default:
        return default
    else:
        raise ArgumentError('Argument %s is required.' % key)


@log_exceptions
def get_from_xensource_inventory(key):
    if os.path.isfile(XS_INVENTORY_PATH) == False:
        raise XenAPI.Failure(
            ['NO_INVENTORY_FILE', "The XenSource Inventory file is missing."])
    fh = open(XS_INVENTORY_PATH, "r")
    data = fh.readlines()
    fh.close()
    for line in data:
        if line.find(key) > -1:
            values = line.split('\'')
            return values[1]
    return XenAPI.Failure('Error reading %s from %s' % (key, XS_INVENTORY_PATH))


############# SSH KEY SETUP ##########################

def install_ssh_key(session, vm_ref, ip, username, password):
    """Install Dom0 public key in droid VM"""
    setup_public_ssh_key()

    fh = open(SSH_PUBLIC_KEY, 'r')
    public_key = fh.read()
    fh.close()

    # Remove any host key previously installed for the specified IP address
    call = ["/bin/sed", "-i", "/%s/d" % ip, SSH_HOST_KEYS]
    make_local_call(call)

    cmd1 = ["mkdir", "-p", "/root/.ssh"]
    cmd2 = ["echo", "\"%s\"" %
            public_key.strip(), ">>", "/root/.ssh/authorized_keys"]
    cmd_str = "%s; %s" % (" ".join(cmd1), " ".join(cmd2))

    log.debug("Install SSH key command string: %s" % cmd_str)
    ssh_command(ip, username, password, cmd_str,
                "Installing SSH Key")["stdout"]

    # Disable hostkey checking
    call = [SSH, '-o', 'StrictHostKeyChecking=no', ip]
    make_local_call(call)

    return True


def setup_public_ssh_key():
    if not os.path.exists(SSH_PUBLIC_KEY):
        call = ['/usr/bin/ssh-keygen', '-f', SSH_PUBLIC_KEY.replace('.pub', ''),
                '-N', '']
        make_local_call(call)

######################################################


@log_exceptions
def inject_ssh_key(session, args):
    """Inject Dom0's public SSH key into a guest VM"""
    vm_ref = validate_exists(args, 'vm_ref')
    mip = validate_exists(args, 'mip')
    username = validate_exists(args, 'username')
    password = validate_exists(args, 'password')

    log.debug("Call to Inject Dom0's SSH key into %s" % vm_ref)
    install_ssh_key(session, vm_ref, mip, username, password)
    return json_dumps("OK")


def get_vm_ips(session, vm_ref):
    guest_metrics_ref = session.xenapi.VM.get_guest_metrics(vm_ref)
    networks = session.xenapi.VM_guest_metrics.get_networks(guest_metrics_ref)
    res = {}
    for k, v in networks.items():
        if k.endswith('ip'):
            res["eth%s" % (k.replace('/ip', ''))] = v
    return res


@log_exceptions
def set_nic_device_status(session, arg):
    """Set an ifconfig ethX interface up or down."""
    device = validate_exists(arg, 'device', None, True)
    status = validate_exists(arg, 'status', None, True)
    res = make_local_call([IFCONFIG, device, status])
    if res['returncode'] != 0:
        msg = "ERR: Failed to set device status. %s" % res['stderr']
        log.error(msg)
        return json_dumps(msg)
    return json_dumps("OK")


@log_exceptions
def get_local_device_linkstate(session, arg):
    """ Return current operstate of network device."""

    res = {}
    device = validate_exists(arg, 'device', None, True)

    output = make_local_call([IFCONFIG, device])['stdout']
    if 'UP' in output:
        res['operstate'] = 'up'
    else:
        res['operstate'] = 'down'
    if 'RUNNING' in output:
        res['carrier'] = 'running'
    else:
        res['carrier'] = ''

    output = make_local_call([ETHTOOL, device])['stdout']
    if 'Link detected: yes' in output:
        res['link'] = 'yes'
    elif 'Link detected: no' in output:
        res['link'] = 'no'
    else:
        res['link'] = 'unknown'

    return json_dumps(res)


def save_bugtool():
    """Saves a bugtool and returns the name"""
    log.debug("Collecting a bugtool report")
    call = ["xen-bugtool", "--yestoall"]
    info = make_local_call(call)["stdout"]
    where = info.find('/var/opt/xen/bug-report')
    bugtool_loc = ((info[where:]).split())[0]
    log.debug("Bugtool saved: %s" % bugtool_loc)
    return bugtool_loc


def run_ack_logrotate(session, args):
    """Run logrotate for ACK logs"""
    release_logging()
    ack_logrotate_dconf = '/etc/logrotate.d/autocertkit'
    try:
        shutil.copyfile(LOGROTATE_CONF_LOC, ack_logrotate_dconf)
        call = ['/usr/sbin/logrotate', '-f', ack_logrotate_dconf]
        res = make_local_call(call, False)
    except Exception as e:
        return json_dumps(str(e))
    finally:
        configure_logging()
    if res['returncode'] != 0:
        msg = "ERR: Failed to run logrotate."
        log.error("%s: %s" % (msg, res['stderr']))
    else:
        msg = "logrotate executed successfully."
        log.debug(msg)

    return json_dumps(msg)


############### TCPDUMP Setup #########################

@log_exceptions
def deploy_tcpdump(session, args):
    """Install tcpdump on a specified VM"""
    log.debug("deploy tcpdump plugin call")
    vm_ref = validate_exists(args, 'vm_ref')

    if not session.xenapi.VM.get_is_control_domain(vm_ref):
        mip = validate_exists(args, 'mip')
        username = validate_exists(args, 'username')
        password = validate_exists(args, 'password')
        # Only setup tcpdump if not control domain
        # - that already has tcpdump installed.
        i = 0
        limit = 10
        while i < limit:
            try:
                install_rpm(session, vm_ref, mip, username, password, TCPDUMP_RPM)
                break
            except:
                log.debug(
                    "Exception raised attempting to deploy tcpdump. Attempt %d" % i)
                time.sleep(8)  # Sleep 8 seconds
                i = i + 1  # Increment counter
                if i == limit:
                    raise PluginError("Plugin Error: Cannot deploy tcpdump")
    else:
        call = fr'''rpm -q tcpdump || rpm -U {INSTALL_DIR}/{TCPDUMP_RPM}'''
        make_local_call(call, shell=True)

    log.debug("tcpdump installation completed")
    return json_dumps("OK")

@log_exceptions
def start_tcpdump_server(session, args):
    """Start up tcpdump on the server. """

    ip = validate_exists(args, 'ip')
    iface = validate_exists(args, 'iface')

    kill_processes('tcpdump')

    # Check for tcpdump existence
    if not process_running(TCPDUMP):
        log.debug("tcpdump is not running - start process")

        # Start tcpdump - need to ensure we don't block
        call = "nohup %s -s 128 -n -i %s src host %s -w tcpdump.pcap &" % (TCPDUMP, iface, ip)
        log.debug("About to start tcpdump server (%s)" % call)
        subprocess.Popen(call, shell=True)
        log.debug("Call executed")

    else:
        raise Exception("ERR: did not kill all tcpdump processes")
    
    return json_dumps("OK")

@log_exceptions
def kill_tcpdump_server(session, args):
    """ Kill tcpdump on the server. """
    kill_processes('tcpdump')

    # Check for tcpdump existence
    if not process_running(TCPDUMP):
        log.debug("Call executed")
    else:
        raise Exception("ERR: did not kill tcpdump process")
    
    return json_dumps("OK")
    
@log_exceptions
def get_tcpdump_data(session, args):
    """ Get tcpdump data, actually the lengths. """
    call = "tcpdump -r tcpdump.pcap -n | grep -o 'length [0-9]*' | awk '{sum += $2} END {print sum}'"
    tcpdump_res = make_local_call(call, shell=True)["stdout"].split('\n')
    call = "rm -rf tcpdump.pcap"
    make_local_call(call, shell=True)
    log.debug(tcpdump_res)
    return json_dumps(tcpdump_res)


############### IPERF Setup #########################


def install_iperf(session, vm_ref, ip, username, password):
    """Install iperf rpm on a droid vm"""
    call = ['/usr/bin/scp',
            "-o", "StrictHostKeyChecking=no",
            "/opt/xensource/packages/files/auto-cert-kit/%s" % IPERF_RPM,
            'root@%s:' % ip]
    log.debug(call)
    make_local_call(call)
    cmd_str = "rpm -U /root/%s" % IPERF_RPM
    log.debug(cmd_str)
    ssh_command(ip, username, password, cmd_str)["stdout"]


@log_exceptions
def upload_file(session, vm_ref, ip, username, password, file):
    """upload one file to VM"""
    call = ['/usr/bin/scp',
            "-o", "StrictHostKeyChecking=no",
            "/opt/xensource/packages/files/auto-cert-kit/%s" % file,
            'root@%s:' % ip]
    log.debug(call)
    make_local_call(call)


@log_exceptions
def run_command(session, vm_ref, ip, username, password, cmd):
    """run shell command on VM"""
    log.debug(cmd)
    return ssh_command(ip, username, password, cmd)


def install_rpms(session, vm_ref, ip, username, password, rpms):
    """install a group of rpm"""
    for rpm in rpms:
        upload_file(session, vm_ref, ip, username, password, rpm)
    rpm_paths = ["/root/%s" % i for i in rpms]
    cmd = "rpm -U %s --nosignature" % ' '.join(rpm_paths)
    run_command(session, vm_ref, ip, username, password, cmd)


def install_rpm(session, vm_ref, ip, username, password, rpm):
    """install one rpm"""
    install_rpms(session, vm_ref, ip, username, password, [rpm])


def install_vf_driver(session, vm_ref, ip, username, password, package, driver_name):
    """Install VF driver rpm on a droid vm"""
    if package:
        install_rpm(session, vm_ref, ip, username, password, package)

    if driver_name:
        cmd = "echo %s > /etc/modules-load.d/%s.conf" % (
            driver_name, driver_name)
        run_command(session, vm_ref, ip, username, password, cmd)


def validate_xml_key(key):
    """Check that a key will be acceptable for an XML attribute
    there are some cases, where invalid keys will cause things
    to break when re-importing."""

    # Check that first character of key is not a number
    valid_key = re.compile(r'^[a-zA-Z].*')
    if valid_key.match(key):
        return True
    else:
        return False


def json_dumps(data):
    return json.dumps(data, indent=2, separators=(',', ': '))


@log_exceptions
def deploy_iperf(session, args):
    """Install iPerf on a specified VM"""
    log.debug("deploy iperf plugin call")
    vm_ref = validate_exists(args, 'vm_ref')

    if not session.xenapi.VM.get_is_control_domain(vm_ref):
        mip = validate_exists(args, 'mip')
        username = validate_exists(args, 'username')
        password = validate_exists(args, 'password')
        # Only setup iperf if not control domain
        # - that already has iperf installed.
        i = 0
        limit = 10
        while i < limit:
            try:
                install_iperf(session, vm_ref, mip, username, password)
                break
            except:
                log.debug(
                    "Exception raised attempting to deploy iperf. Attempt %d" % i)
                time.sleep(8)  # Sleep 8 seconds
                i = i + 1  # Increment counter
                if i == limit:
                    raise PluginError("Plugin Error: Cannot deploy Iperf")
    else:
        call = fr'''rpm -q iperf || rpm -U {INSTALL_DIR}/{IPERF_RPM}'''
        make_local_call(call, shell=True)

    log.debug("iPerf installation completed")
    return json_dumps("OK")


@log_exceptions
def deploy_vf_driver(session, args):
    """Install VF driver on a specified VM"""
    log.debug("deploy VF driver plugin call")
    vm_ref = validate_exists(args, 'vm_ref')
    mip = validate_exists(args, 'mip')
    username = validate_exists(args, 'username')
    password = validate_exists(args, 'password')
    package = args['package']
    driver_name = args['driver_name']

    if not session.xenapi.VM.get_is_control_domain(vm_ref):
        i = 0
        limit = 10
        while i < limit:
            try:
                install_vf_driver(session, vm_ref, mip, username,
                                  password, package, driver_name)
                break
            except:
                log.debug(
                    "Exception raised attempting to deploy VF driver. Attempt %d" % i)
                i += 1
                if i == limit:
                    raise PluginError("Plugin Error: Cannot deploy VF driver")
                time.sleep(8)

    log.debug("VF driver installation completed")
    return json_dumps("OK")


def shell_run_on_guest(session, vm_ref, mip, username, password, cmd):
    if session.xenapi.VM.get_is_control_domain(vm_ref):
        return {"returncode": -1, "stdout": "", "stderr": "DON'T run in control domain"}

    return run_command(session, vm_ref, mip, username, password, cmd)


def shell_run_on_host(session, cmd):
    try:
        res = make_local_call([cmd], True, std_out=subprocess.PIPE, shell=True)
    except Exception as e:
        log.debug("Exception: %s" % str(e))
        res = {"returncode": -1, "stdout": "", "stderr": ""}
    return res


@log_exceptions
def shell_run(session, args):
    """General interface execute shell command(s) on host and even guest VM"""
    log.debug("shell run plugin call")
    vm_ref = validate_exists(args, 'vm_ref', None, False)
    mip = validate_exists(args, 'mip', "", False)
    username = validate_exists(args, 'username', "", False)
    password = validate_exists(args, 'password', "", False)
    cmd = validate_exists(args, 'cmd')
    cmd = binascii.unhexlify(cmd).decode()

    if vm_ref:
        res = shell_run_on_guest(session, vm_ref, mip, username, password, cmd)
    else:
        res = shell_run_on_host(session, cmd)

    return json_dumps([res])


def get_pci_id(bus_id):
    """Return the PCI id for a specified bus location"""
    call = ['/sbin/lspci', '-n', '-s', bus_id]
    try:
        res = make_local_call(call)
        return res["stdout"].split()[2]
    except Exception as e:
        log.debug("Exception: %s" % str(e))


def get_pci_description(bus_id):
    """Return the PCI description for a specified bus location"""
    log.debug("Getting decription for PCI device at bus id: %s" % bus_id)
    devices = PCIDevices()

    if bus_id not in devices.devs.keys():
        # Biosdevname returns shortened Bus IDs, so check that.
        # i.e. instead of '0000:02:00.1' --> '02:00.1'
        # remove front 5 characters.
        short_bus_id = bus_id[5:]
        if short_bus_id not in devices.devs.keys():
            raise Exception("Error: the Bus ID '%s' cannot be found in the PCI database" %
                            short_bus_id)
        else:
            # Only the short ID is found in the record, so use this.
            bus_id = short_bus_id

    dev_rec = devices.devs[bus_id]

    IDS = PCIIds.read()
    vendor = IDS.findVendor(dev_rec['vendor'])
    description = IDS.findDevice(dev_rec['vendor'], dev_rec['device'])
    return "%s %s" % (vendor, description)


def get_pci_subsystem(bus_id):
    """Return the PCI subsystem information for a specified bus location:"""
    log.debug("Getting subsystem for PCI device at bus id: %s" % bus_id)

    call = ['/sbin/lspci', '-nn', '-v', '-s', bus_id]
    try:
        res = make_local_call(call)
        return res["stdout"].split('\n')[1].strip()
    except Exception as e:
        log.debug("Exception: %s" % str(e))
    return ""


@log_exceptions
def create_output_package(session, args):
    """Create an output package for submission to XenServer"""

    dt = datetime.datetime.now()
    tarfile_loc = "/root/ack-submission-%s.tar.gz" % dt.strftime(
        '%H-%M-%d-%m-%Y')

    bugtool_loc = save_bugtool()

    tar = tarfile.open(tarfile_loc, 'w:gz')

    def add_if_exists(file_loc):
        if os.path.exists(file_loc):
            tar.add(file_loc)
        else:
            log.debug(
                "Cannot add %s to output package, does not exist" % file_loc)

    tar.add(bugtool_loc)
    tar.add("%s/test_run.conf" % INSTALL_DIR)

    add_if_exists(LMBENCH_RESULTS_DIR)
    add_if_exists("%s/iozone.log" % INSTALL_DIR)
    add_if_exists("%s/bonnie.log" % INSTALL_DIR)

    tar.add("/root/results.txt")
    tar.close()
    return json_dumps(tarfile_loc)


def _pre_tampa_biosdevname():
    """Pre Tampa, we have to use the old biosdevname library"""
    import xcp.biosdevname
    biosdevobj = BiosDevName()
    if not biosdevobj.run():
        raise Exception("Error exceuting biosdevname XCP library.")

    type_key = 'Kernel name'
    pattern = re.compile(r'\d*:?[a-f0-9]+:[a-f0-9]+\.[a-f0-9]')

    return [device for device in biosdevobj.devices
            if (device[type_key].startswith('eth') and pattern.match(device['Bus Info']))]


def compat_biosdevname():
    """Return biosdevname, irrespective of system."""
    try:
        import xcp.net.biosdevname
    except ImportError:
        return _pre_tampa_biosdevname()

    devs = xcp.net.biosdevname.all_devices_all_names()

    devices = []
    pattern = re.compile(r'\d*:?[a-f0-9]+:[a-f0-9]+\.[a-f0-9]')

    for eth, rec in devs.items():
        if pattern.match(rec['Bus Info']):
            log.debug("Found %s" % eth)
            devices.append(rec)

    return devices


@log_exceptions
def get_network_devices(session, args):
    """Return a list of network devices and their corresponding properties"""
    log.debug("Getting network devices Plugin Call")

    devices = []
    devs = compat_biosdevname()

    # Filter for only network devices.
    for device in devs:
        log.debug("Device: %s" % device)
        pci_id = get_pci_id(device['Bus Info'])
        device['PCI_id'] = pci_id
        log.debug("Bus Id %s" % device['Bus Info'])
        device['PCI_description'] = get_pci_description(device['Bus Info'])
        device['PCI_subsystem'] = get_pci_subsystem(device['Bus Info'])
        devices.append(device)

    return json_dumps(devices)


def _get_local_storage_disk(session):
    disk_path = get_from_xensource_inventory('PRIMARY_DISK')
    log.debug("Local Storage Disk Path: %s" % disk_path)
    if os.path.islink(disk_path):
        return os.path.basename(os.readlink(disk_path))
    return os.path.basename(disk_path)


__scsi_id_regex = re.compile("([\-\d\w\/]+)\-part\d+")


def _get_local_storage_disks(session):
    """ Find all local disk """

    disks = {}
    pool = session.xenapi.pool.get_all()[0]
    host = session.xenapi.pool.get_master(pool)
    srs = session.xenapi.SR.get_all()
    for sr in srs:
        srtype = session.xenapi.SR.get_type(sr)
        if srtype not in ["ext", "lvm"]:
            continue
        for pbd in session.xenapi.SR.get_PBDs(sr):
            if session.xenapi.PBD.get_host(pbd) != host:
                continue
            dev_con = session.xenapi.PBD.get_device_config(pbd)
            if "device" not in dev_con:
                continue
            iface_path = dev_con["device"]
            m = __scsi_id_regex.match(iface_path)
            if m:
                iface_path = m.groups()[0]
            if os.path.islink(iface_path):
                disks[os.path.basename(os.readlink(iface_path))] = sr
            else:
                disks[os.path.basename(iface_path)] = sr

    return disks


__bus_id_regex = re.compile("[0-9a-fA-F]{2}\:[0-9a-fA-F]{2}\.[0-9a-fA-F]")
__pci_addr_regex = re.compile(
    "^[0-9a-fA-F]{4}\:[0-9a-fA-F]{2}\:[0-9a-fA-F]{2}\.[0-9a-fA-F]$")


def _is_bus_id(bus_id):
    """ Check given bus_id is format of bus id """
    return __bus_id_regex.match(bus_id[-7:])


def _is_pci_addr(pci_addr):
    """ Check given pci_addr is format of PCI address """
    return __pci_addr_regex.match(pci_addr)


def get_dev_pci_addr(full_path):
    """ Get device PCI address from full path
    :param full_path: device full path in /sys, e.g.
        ../../devices/pci0000:00/0000:00:01.0/0000:03:00.0/host0/target0:2:0/0:2:0:0/block/sda
    :return: index and device PCI address, e.g. (5, 0000:03:00.0)
    """
    tmp_list = full_path.split(os.sep)
    for index, value in reversed(list(enumerate(tmp_list))):
        if _is_pci_addr(value):
            return index, value
    return -1, None


def _get_bus_paths(disks):
    """ Find bus path of given disk. """
    # Looking for bus path for disks
    device_path = "/sys/dev/block"
    bus_paths = {}
    for filename in os.listdir(device_path):
        fullpath = device_path + os.sep + filename
        if os.path.islink(fullpath) and os.path.basename(os.readlink(fullpath)) in disks.keys():
            bus_paths[os.readlink(fullpath)] = disks[
                os.path.basename(os.readlink(fullpath))]

    # paths in the list may not be the bus path but sym link to device.
    # If bus path does not include bus id, follow link to get bus path
    modified_bus_path = {}
    for bus_path, sr in bus_paths.items():
        path_tokens = bus_path.split(os.sep)
        _, pci_addr = get_dev_pci_addr(bus_path)
        if len(path_tokens) < 5 or not _is_bus_id(pci_addr):
            disk = path_tokens[-1]
            newpath = "sys/block/%s/device" % disk
            if os.path.exists(newpath) and os.path.islink(newpath):
                linked_path = os.readlink(newpath)
                if len(linked_path) < 5 or not _is_bus_id(linked_path.split(os.sep)[4]):
                    log.debug("%s or %s is not proper bus path. Failed to obtain bus path for %s" %
                              (bus_path, linked_path, disk))
                else:
                    modified_bus_path[linked_path] = sr
            else:
                log.debug(
                    "Cannot find physical device or bus path of %s. Perhaps it is a logical volume." % disk)
        else:
            modified_bus_path[bus_path] = sr

    return modified_bus_path


def find_dir(dirpath, dirname, max_depth=2):
    """Find a file in a given directory, recursing a limited number of times"""

    def _find(path, dname):
        """Inner function for checking a directory
        for the existance of a file"""
        for root, dirs, filenames in os.walk(path):
            log.debug("Directories: %s" % dirs)
            if dname in dirs:
                return True, os.sep.join([root, dname])
            else:
                return False, dirs

    results = []
    paths = [dirpath]

    for depth in range(max_depth):
        log.debug("Directory Depth: %d" % depth)

        # Take a copy of the list, so as to
        # force exiting the iteration to count depth.
        for path in list(paths):
            log.debug("Path: %s" % path)

            # Ensure that the path actually exists
            if os.path.exists(path):
                val, res = _find(path, dirname)
            else:
                # If the path doesn't exist, ignore it.
                continue
            # Check the result of the find.
            # If True, we found a result, so append it.
            # If False, we may have returned sub-directories.
            if val:
                results.append(res)
            else:
                # Check whether any sub directories were returned
                if res:
                    # Append sub directories to the paths list
                    # for searching the next level down.
                    for item in res:
                        paths.append("/".join([path, item]))

    return results


@log_exceptions
def get_local_storage_devices(session, args):
    """Return a list of local storage devices and their corresponding properties"""

    # Ensure that any exceptions raised as a result of find a non-expected device
    # passes back a failure message without halting execution.

    try:

        disks = _get_local_storage_disks(session)
        log.debug("Local disks found: %s" % disks)
        bus_paths = _get_bus_paths(disks)
        log.debug("Buses found: %s" % bus_paths)

        if len(bus_paths) == 0:
            return json_dumps([{'Exception': 'Cannot find Storage interface.'}])

        # Enumerate PCI Devices
        devices = PCIDevices()

        storage_devices = []
        for bus_path, sr in bus_paths.items():

            index, bus_id = get_dev_pci_addr(bus_path)

            if bus_id.startswith('0000:'):
                # We only care about the shortened id
                bus_id = bus_id[5:]

            # Copy dictionary record for device at specified bus location
            device = dict(devices.devs[bus_id])

            device['PCI_id'] = get_pci_id(bus_id)
            device['PCI_description'] = get_pci_description(bus_id)
            device['PCI_subsystem'] = get_pci_subsystem(bus_id)

            device['sr'] = sr
            driver_root_dir = "/sys/%s" % '/'.join(
                bus_path.split('/')[2:index+1])

            log.debug("Searching for driver sym link in '%s'" %
                      driver_root_dir)

            driver_links = find_dir(driver_root_dir, 'driver')

            if driver_links:
                log.debug("Found the following driver sym-links: %s" %
                          driver_links)

                # Take the first link - there should only be one, but this needs
                # investigation on more bits of hardware, so let's not fail if there
                # does exist more than one link.
                driver_sym = driver_links[0]
                log.debug("Reading driver from symlink: %s" % driver_sym)

                # Just check the path is still there.
                if os.path.exists(driver_sym):
                    device['driver'] = os.path.basename(
                        os.readlink(driver_sym))
            if not device in storage_devices:
                storage_devices.append(device)

        return json_dumps(storage_devices)

    except Exception as e:
        log.debug("Could not get local storage info. Exception: %s" % str(e))
        return json_dumps([{'Exception': 'StorageInfoNotAvailable', 'Exception_Info': str(e)}])


@log_exceptions
def set_hw_offload(session, args):
    """Set, using ethtool, whether a specified
    hw offload is turned on or off in the devices
    driver"""
    eth_dev = validate_exists(args, 'eth_dev')
    offload_type = validate_exists(args, 'offload')
    offload_state = validate_exists(args, 'state')
    call = [ETHTOOL, '-K', eth_dev, offload_type, offload_state]
    log.debug("Ethtool Command: %s" % call)
    return json_dumps(make_local_call(call)["stdout"])


@log_exceptions
def get_hw_offloads_from_core(session, args):
    """Return a dictionary object specifying offload protocols by
    checking /sys/class/net/ethX """
    eth_dev = validate_exists(args, 'eth_dev')
    if eth_dev.startswith('xenbr'):
        eth_dev = eth_dev.replace('xenbr', 'eth')

    rec = {}
    flag = int(make_local_call(
        ['cat', '/sys/class/net/%s/features' % eth_dev])['stdout'], 16)

    for offload, offset in OFFLOAD_FLAGS_OFFSET.items():
        if offset & flag:
            rec[offload] = 'on'
        else:
            rec[offload] = 'off'

    return json_dumps(rec)


@log_exceptions
def get_hw_offloads(session, args):
    """Return a dictionary object specifying offload protocols,
    and whether they are on or off (as true or false)"""
    eth_dev = validate_exists(args, 'eth_dev')
    call = [ETHTOOL, '-k', eth_dev]
    offloads = make_local_call(call)["stdout"].split('\n')
    # Remove the item at the top of the list
    # "Offload parameters for ethX:"
    offloads.pop(0)
    rec = {}
    for line in offloads:
        arr = line.strip().split(': ')
        if len(arr) != 2:
            raise Exception("Unexpected format from ethtool -k " +
                            "has been returned. %s" % offloads)
        if arr[0] in OFFLOAD_CODES:
            rec[OFFLOAD_CODES[arr[0]]] = arr[1]
    return json_dumps(rec)


@log_exceptions
def get_network_backend(session, args):
    """Return the networking backend used by the pool"""
    fh = open('/etc/xensource/network.conf', 'r')
    backend = fh.read()
    fh.close()
    return json_dumps(backend.strip())


@log_exceptions
def set_network_backend_pool(session, args):
    """Set the backend used by the pool"""
    backend = validate_exists(args, 'backend')
    pool_ref = session.xenapi.pool.get_all()[0]
    master_ref = session.xenapi.pool.get_master(pool_ref)
    result = ""
    for host_ref in session.xenapi.host.get_all():
        out = session.xenapi.host.call_plugin(host_ref,
                                              'autocertkit',
                                              'set_network_backend',
                                              args)
        result += "%s: %s " % (host_ref, out)

    return json_dumps(result)


@log_exceptions
def set_network_backend(session, args):
    """Set the backend used by the pool"""
    # Note, this requires a host reboot to become effective
    backend = validate_exists(args, 'backend')
    call = ['/opt/xensource/bin/xe-switch-network-backend', backend]
    return json_dumps(make_local_call(call)["stdout"])


@log_exceptions
def iperf_test(session, args):
    """Run iperf in client mode against a provided target host"""
    dst_host = validate_exists(args, 'dst')
    vm_ref = validate_exists(args, 'vm_ref')
    #params = validate_exists(args, 'params')

    this_host_uuid = get_from_xensource_inventory('INSTALLATION_UUID')
    host_ref = session.xenapi.VM.get_resident_on(vm_ref)
    if session.xenapi.host.get_uuid(host_ref) != this_host_uuid:
        return session.xenapi.host.call_plugin(host_ref, 'autocertkit',
                                               'iperf_test',
                                               args)

    window_size = validate_exists(args, 'window_size', False)
    format = validate_exists(args, 'format', False)
    buffer_length = validate_exists(args, 'buffer_length', False)
    thread_count = validate_exists(args, 'thread_count', False)

    call = [IPERF, '-y', 'csv']

    def copy(param, cmd_arg):
        if param:
            call.append(cmd_arg)
            call.append(param)

    copy(window_size, '-w')
    copy(format, '-f')
    copy(buffer_length, '-l')
    copy(thread_count, '-P')
    copy(dst_host, '-c')

    # Print MTU size
    call.append('-m')

    return json_dumps(make_local_call(call)["stdout"])


def parse_proc_net_dev(data):
    """Taking the contents of /proc/net/dev parse to provide a record"""
    lines = data.split('\n')

    header = lines[1]
    _, rx_cols, tx_cols = header.split("|")
    rx_cols = ["rx_%s" % x for x in rx_cols.split()]
    tx_cols = ["tx_%s" % x for x in tx_cols.split()]
    cols = rx_cols + tx_cols

    ifaces = {}
    for line in lines[2:]:
        if not line.find(":"):
            continue
        iface, data = line.split(":")
        iface_data = dict(list(zip(cols, data.split())))
        ifaces[iface.strip()] = iface_data

    return ifaces


@log_exceptions
def add_route(session, args):
    """Add a network table route to a particular VM"""
    vm_ref = validate_exists(args, 'vm_ref')
    device = validate_exists(args, 'device')
    dest_ip = validate_exists(args, 'dest_ip')
    gw = validate_exists(args, 'gw', required=False)
    mask = validate_exists(args, 'mask', required=False)
    src = validate_exists(args, 'src', required=False)

    log.debug("add_route %s %s %s" % (vm_ref, device, dest_ip))

    if session.xenapi.VM.get_is_control_domain(vm_ref):

        # Check if we need to relay this call to another host
        # in the pool.

        this_host_uuid = get_from_xensource_inventory('INSTALLATION_UUID')
        host_ref = session.xenapi.VM.get_resident_on(vm_ref)
        if session.xenapi.host.get_uuid(host_ref) != this_host_uuid:
            return session.xenapi.host.call_plugin(host_ref, 'autocertkit',
                                                   'add_route',
                                                   args)

        bridge = _get_local_device_bridge(session, device)
        # Handle the case that we are dealing with Dom0
        # 1. Setup the correct routing entry in Dom0's routing table

        # Handle the default route case
        if dest_ip == '0.0.0.0' and mask == '0.0.0.0' and gw:

            log.debug("Removing default gateway, before adding it back in")
            call = [IP, "route", "del", "default"]
            make_local_call(call)

            call = [IP,
                    "route",
                    "add",
                    "default",
                    "via",
                    gw,
                    "dev",
                    bridge]

        else:
            call = [IP,
                    "route",
                    "add",
                    "%s/32" % dest_ip,
                    "dev",
                    bridge]

    else:
        # Handle the case we are adding a route to a VM
        vm_m_ip = validate_exists(args, 'mip')
        call = [SSH,
                vm_m_ip, IP,
                "route",
                "add",
                "%s/32" % dest_ip,
                "dev",
                device]
        if src:
            call += ["src", src]

    return json_dumps(make_local_call(call)["stdout"])


@log_exceptions
def remove_route(session, args):
    """Remove an IP route that has been setup"""
    vm_ref = validate_exists(args, 'vm_ref')
    dest_ip = validate_exists(args, 'dest_ip')

    if session.xenapi.VM.get_is_control_domain(vm_ref):
        call = [IP, 'route', 'del', dest_ip]
        make_local_call(call)
    else:
        raise Exception("Not yet supported")

    return json_dumps("OK")


@log_exceptions
def set_kernel_parameter(key, value, mip=None):
    """
    Delete all line which contains key in config file, and then write key=value to file,
    Will take effect after reload(sysctl --sytstem) or reboot
    """
    conf_file = "/etc/sysctl.d/ack.conf"
    cmd = "sed -i '/^%s=/d' %s; echo '%s=%s'>>%s" % (key, conf_file, key, value, conf_file)
    call = [SSH, mip, cmd]
    make_local_call(call)
    

@log_exceptions
def reset_arp(session, args):
    """Ensure that the switch knows which interfaces to 
    communicate with the VM over. If sharing the same subnet
    it is possible for eth0 to reply for eth1. We want to prevent
    that and ensure the switch knows which interface on the VM
    to send traffic too."""

    vm_ref = validate_exists(args, 'vm_ref')
    mode = validate_exists(args, 'mode', '0', False)

    log.debug("Reset ARP for VM %s" % vm_ref)

    arp_ipv4_ignore_config = "net.ipv4.conf.all.arp_ignore=1"

    if session.xenapi.VM.get_is_control_domain(vm_ref):

        # Handle the case that we are dealing with Dom0
        call = [SYSCTL, arp_ipv4_ignore_config]
        make_local_call(call)

        # Determine the host reference
        host_ref = session.xenapi.VM.get_resident_on(vm_ref)
        pifs = session.xenapi.host.get_PIFs(host_ref)
        for pif in pifs:
            device = session.xenapi.PIF.get_device(pif)

            # Execute a gratuitus ARP for the device in question
            # translate device name into bridge
            bridge = _get_local_device_bridge(session, device)

            log.debug("About to send gARP out on %s" % bridge)

            bridge_dev = _get_local_device(bridge)

            if not bridge_dev.ip:
                log.debug("Error: cannot find IP for bridge %s" % bridge)
            else:
                call = [ARPING, "-c", '10', '-A', '-I', bridge, bridge_dev.ip]
                make_local_call(call)

    else:
        # Handle the Droid VM case
        vm_m_ip = validate_exists(args, 'mip')

        arp_ignore_value = 1 if mode == '0' else 0
        rp_filter_value = 0 if mode == '0' else 1

        # Global ARP Ignore
        set_kernel_parameter("net.ipv4.conf.all.arp_ignore", arp_ignore_value , vm_m_ip)
        set_kernel_parameter("net.ipv4.conf.default.arp_ignore", arp_ignore_value , vm_m_ip)

        '''
        # Revert arp_ignore to default 0, otherwise DLVM (CentOS 7.2) no interface will reply arp query.
        # Because verified https://access.redhat.com/solutions/30564, but does not work
        cmd = "%s net.ipv4.conf.all.arp_filter=1; %s net.ipv4.conf.default.arp_filter=1; " \
              "%s net.ipv4.conf.all.arp_announce=2; %s net.ipv4.conf.default.arp_announce=2;" \
              % (SYSCTL, SYSCTL, SYSCTL, SYSCTL)
        call = [SSH, vm_m_ip, cmd]
        make_local_call(call)
        '''

        # In previous DLVM (CentOS 5), rp_filter is 0. If don't set in new DLVM, then Multicast test
        # will be failed using interfaces in same one subnet
        # Change global setting
        set_kernel_parameter("net.ipv4.conf.all.rp_filter", rp_filter_value, vm_m_ip)
        set_kernel_parameter("net.ipv4.conf.default.rp_filter", rp_filter_value, vm_m_ip)

        # Change current existing interface
        cmd = """ip -o link | awk '{if($2 ~ "eth.+:") print $2}' | sed 's/:$//'"""
        call = [SSH, vm_m_ip, cmd]
        iface_list = make_local_call(call)["stdout"].split()
        for iface in iface_list:
            set_kernel_parameter("net.ipv4.conf.%s.arp_ignore" % iface, arp_ignore_value, vm_m_ip)
            set_kernel_parameter("net.ipv4.conf.%s.rp_filter" % iface, rp_filter_value, vm_m_ip)

        # reload sysctl.conf variables
        call = [SSH, vm_m_ip, SYSCTL, "--system"]
        make_local_call(call)

        # log arp
        call = [SSH, vm_m_ip, "cat", "/proc/net/arp"]
        make_local_call(call)

        # log sysctl
        call = [SSH, vm_m_ip, SYSCTL, "-A"]
        make_local_call(call)

    return json_dumps("OK")


def get_iface_stats(session, args):
    """Use ethtool to return a list of statistics for a given interface"""
    vm_ref = validate_exists(args, 'vm_ref')
    iface_name = validate_exists(args, 'iface')
    log.debug("Iface passed in %s" % iface_name)
    data = None
    arch = None

    if session.xenapi.VM.get_is_control_domain(vm_ref):
        host_ref = session.xenapi.VM.get_resident_on(vm_ref)
        this_host_uuid = get_from_xensource_inventory('INSTALLATION_UUID')

        if host_ref == session.xenapi.host.get_by_uuid(this_host_uuid):
            # Execute call locally
            call = [CAT, '/proc/net/dev']
            data = make_local_call(call)["stdout"]
            log.debug("Net Stats: %s" % data)
            call = [UNAME, '-i']
            arch = make_local_call(call)["stdout"]

        else:
            # Proxy the command to the correct host
            return session.xenapi.host.call_plugin(host_ref,
                                                   'autocertkit',
                                                   'get_iface_stats',
                                                   args)
    else:
        # Dealing with a non-control domain. SSH and obtain result
        vm_m_ip = validate_exists(args, 'mip')
        log.debug("IP address for VM '%s' is '%s'" % (vm_ref,
                                                      vm_m_ip))

        # Note, we rely on an SSH key being setup for this
        # droid VM.

        call = [SSH, vm_m_ip, CAT, '/proc/net/dev']
        log.debug("About to make SSH call: %s" % call)

        data = make_local_call(call)["stdout"]

        call = [SSH, vm_m_ip, UNAME, '-i']
        log.debug("About to make SSH call: %s" % call)
        arch = make_local_call(call)["stdout"]

    if not data:
        log.error("Error: no data obtained from calls")

    if not arch:
        log.error("Error: no arch obtained from calls")

    rec = parse_proc_net_dev(data)

    if iface_name not in rec.keys():
        log.error("Error: could not find iface '%s' in stats (%s)" %
                  (iface_name, rec.keys()))

    device_stats = rec[iface_name]

    # Pass on arch info so that client can work around the wrap enforced
    # with a 32bit bytes counter.
    device_stats['arch'] = arch

    log.debug("Device Stats: %s %s" % (vm_ref, device_stats))

    return json_dumps(device_stats)


@log_exceptions
def get_host_routes(session, args):
    """Return a XML dictionary list of host routes"""
    routes = route.get_all_routes()
    route_recs = [route_obj.get_record() for route_obj in routes]
    return json_dumps(route_recs)

############### Host Crash #######################


@log_exceptions
def force_crash_host(session, args):
    """Forcr crash given host."""

    # Open a system request trigger file.
    fh = open('/proc/sysrq-trigger', 'w')

    # Synchronize data before crash. Ensure actions by flushing stream.
    fh.write('s')
    fh.flush()
    time.sleep(5)

    # Request crashing the host. close() will do the flushing.
    fh.write('c')
    fh.close()

    # Give some time to crash.
    time.sleep(5)


@log_exceptions
def _retrieve_crashdumps_from_xapi(session, host):
    """Search for crashdumps using xapi."""
    cds = session.xenapi.host_crashdump.get_all()
    ret = []
    for cd in cds:
        if not host == session.xenapi.host_crashdump.get_host(cd):
            continue
        ret.append({'host': host,
                    'timestamp': str(session.xenapi.host_crashdump.get_timestamp(cd)),
                    'size': str(session.xenapi.host_crashdump.get_size(cd)),
                    'uuid': session.xenapi.host_crashdump.get_uuid(cd),
                    'other-config': str(session.xenapi.host_crashdump.get_other_config(cd))
                    })

    return ret


CD_PATTERN = re.compile(r'\d{8}\-\d{6}\-.*')


@log_exceptions
def _retrieve_crashdumps(session, host):
    """Search for crashdumps from /var/crash."""
    CD_LOC = '/var/crash'
    if not os.path.isdir(CD_LOC):
        return json_dumps([])

    ret = []
    for apath in os.listdir(CD_LOC):
        if not CD_PATTERN.match(apath):
            continue
        size = 4096  # directory itself is size of 4096
        cdpath = CD_LOC + os.sep + apath
        for logfile in os.listdir(cdpath):
            if not os.path.isfile(cdpath + os.sep + logfile):
                continue
            size += os.path.getsize(cdpath + os.sep + logfile)
        ret.append({'host': host,
                    'timestamp': str(apath),
                    'size': str(size)
                    })

    return ret


def retrieve_crashdumps(session, args):
    """Search all crashdumps and return."""
    if not args or not 'host' in args:
        raise Exception("host is required to obtain crash dump.")

    if args and 'from_xapi' in args and args['from_xapi'] == 'True':
        return json_dumps(_retrieve_crashdumps_from_xapi(session, args['host']))
    return json_dumps(_retrieve_crashdumps(session, args['host']))


############### LMbench Setup #########################
@log_exceptions
def copy_lmbench_config(session, vm_ref, ip, username, password):
    """Copy the LMbench config file to a VM"""
    if not os.path.exists(LMBENCH_CONF_LOC):
        raise Exception("LMbench config file is not present in %s" %
                        LMBENCH_CONF_LOC)

    # Determine where lmbench will be looking for the config
    # file, so that we can copy it to the correct place.
    cmd_str = "/usr/lib/lmbench/scripts/config"
    config_file_name = ssh_command(
        ip, username, password, cmd_str)["stdout"]

    log.debug("Deterined that VM %s needs lmbench config file named: %s" %
              (vm_ref, config_file_name))

    call = ['/usr/bin/scp',
            "-o", "StrictHostKeyChecking=no",
            LMBENCH_CONF_LOC,
            'root@%s:/usr/lib/lmbench/bin/x86_64-linux-gnu/%s' % (ip, config_file_name)]
    log.debug(call)
    return make_local_call(call)["stdout"]


@log_exceptions
def deploy_lmbench(session, args):
    """Install LMbench on a VM"""
    vm_ref = validate_exists(args, 'vm_ref')
    mip = validate_exists(args, 'mip')
    username = validate_exists(args, 'username')
    password = validate_exists(args, 'password')

    if not session.xenapi.VM.get_is_control_domain(vm_ref):
        # Only setup iperf if not control domain
        # - that already has lmbench installed.
        i = 0
        limit = 5
        while i < limit:
            try:
                install_rpm(session, vm_ref, mip, username,
                            password, LMBENCH_RPM)
                copy_lmbench_config(session, vm_ref, mip, username, password)
                break
            except:
                log.debug(
                    "Exception raised attempting to deploy LMbench. Attempt %d" % i)
                time.sleep(5)  # Sleep 5 seconds
                i = i + 1  # Increment counter
                if i == limit:
                    raise Exception("Cannot deploy LMbench")

    log.debug("LMbench installation completed")
    return json_dumps("OK")


@log_exceptions
def retrieve_lmbench_logs(session, args):
    """Copy the LMbench logs back to the log dir on the master host"""
    vm_ref = validate_exists(args, 'vm_ref')
    username = validate_exists(args, 'username')
    password = validate_exists(args, 'password')
    ip_address = validate_exists(args, 'mip')

    # Make sure the logs exists
    results_dir = '/usr/lib/lmbench/results/x86_64-linux-gnu/'
    cmd_str = "ls %s* | wc -l" % results_dir
    log.debug(cmd_str)
    response = ssh_command(ip_address, username, password, cmd_str)["stdout"]

    if int(response) == 0:
        raise Exception(
            "Couldn't find any results files in directory '%s'" % results_dir)

    # Make sure the local lmbench results dir exists
    if not os.path.exists(LMBENCH_RESULTS_DIR):
        os.makedirs(LMBENCH_RESULTS_DIR)

    # Create a directory per VM to save having to rename log files to
    # avoid overwritting other results.
    vm_lmbench_results_dir = "%s/%s" % (LMBENCH_RESULTS_DIR, vm_ref)
    os.mkdir(vm_lmbench_results_dir)

    # SCP the logs to the master host
    call = ["/usr/bin/scp", "-o", "StrictHostKeyChecking=no",
            "root@%s:/usr/lib/lmbench/results/x86_64-linux-gnu/*" % ip_address,
            vm_lmbench_results_dir]

    log.debug(call)
    return json_dumps(make_local_call(call)["stdout"])


def lmbench_test(session):
    """Run LMbench"""
    call = [LMBENCH]
    log.debug(call)
    return make_local_call(call)["stdout"]


############### Iozone Setup #########################

@log_exceptions
def deploy_iozone(session, args):
    """Install Iozone on a VM"""
    vm_ref = validate_exists(args, 'vm_ref')
    mip = validate_exists(args, 'mip')
    username = validate_exists(args, 'username')
    password = validate_exists(args, 'password')

    if not session.xenapi.VM.get_is_control_domain(vm_ref):
        # Only setup iperf if not control domain
        # - that already has iozone installed.
        i = 0
        limit = 5
        while i < limit:
            try:
                install_rpm(session, vm_ref, mip,
                            username, password, IOZONE_RPM)
                break
            except:
                log.debug(
                    "Exception raised attempting to deploy Iozone. Attempt %d" % i)
                time.sleep(5)  # Sleep 5 seconds
                i = i + 1  # Increment counter
                if i == limit:
                    raise Exception("Cannot deploy Iozone")

    log.debug("Iozone installation completed")
    return json_dumps("OK")


@log_exceptions
def retrieve_iozone_logs(session, args):
    """Copy the Iozone logs back to the log dir on the master host"""
    vm_ref = validate_exists(args, 'vm_ref')
    username = validate_exists(args, 'username')
    password = validate_exists(args, 'password')
    ip_address = validate_exists(args, 'mip')

    # Make sure the logs exists
    cmd_str = "test -e /root/localhost.log"
    log.debug(cmd_str)
    response = ssh_command(ip_address, username, password, cmd_str)["stdout"]
    if "error" in response:
        raise Exception("Cannot retrieve Iozone log from VM %s" % vm_ref)

    # SCP the logs to the master host
    call = ["/usr/bin/scp", "-o", "StrictHostKeyChecking=no", "root@%s:/root/localhost.log" %
            ip_address, "/opt/xensource/packages/files/auto-cert-kit/iozone.log"]
    log.debug(call)
    return json_dumps(make_local_call(call)["stdout"])


############### Bonnie++ Setup #########################

@log_exceptions
def deploy_bonnie(session, args):
    """Install Bonnie++ on a VM"""
    vm_ref = validate_exists(args, 'vm_ref')
    mip = validate_exists(args, 'mip')
    username = validate_exists(args, 'username')
    password = validate_exists(args, 'password')

    if not session.xenapi.VM.get_is_control_domain(vm_ref):
        # Only setup iperf if not control domain
        # - that already has bonnie++ installed.
        i = 0
        limit = 5
        while i < limit:
            try:
                install_rpm(session, vm_ref, mip,
                            username, password, BONNIE_RPM)
                ssh_command(mip, username, password,
                            'mkdir -m a=rwx /root/bonnie; useradd citrix; chown citrix /root/bonnie')
                break
            except:
                log.debug(
                    "Exception raised attempting to deploy Bonnie++. Attempt %d" % i)
                time.sleep(5)  # Sleep 5 seconds
                i = i + 1  # Increment counter
                if i == limit:
                    raise Exception("Cannot deploy Bonnie++")

    log.debug("Bonnie++ installation completed")
    return json_dumps("OK")


@log_exceptions
def retrieve_bonnie_logs(session, args):
    """Copy the Bonnie++ logs back to the log dir on the master host"""
    vm_ref = validate_exists(args, 'vm_ref')
    username = validate_exists(args, 'username')
    password = validate_exists(args, 'password')
    ip_address = validate_exists(args, 'mip')

    # Make sure the logs exists
    cmd_str = "test -e /root/localhost.log"
    log.debug(cmd_str)
    response = ssh_command(ip_address, username, password, cmd_str)["stdout"]
    if "error" in response:
        raise Exception("Cannot retrieve Bonnie++ log from VM %s" % vm_ref)

    # SCP the logs to the master host
    call = ["/usr/bin/scp", "-o", "StrictHostKeyChecking=no", "root@%s:/root/localhost.log" %
            ip_address, "/opt/xensource/packages/files/auto-cert-kit/bonnie.log"]
    log.debug(call)
    return json_dumps(make_local_call(call)["stdout"])


############### Main #########################


def handle_ipv4_static_conf(session, vm_uuid, iface, args):
    ip = validate_exists(args, 'ip')
    netmask = validate_exists(args, 'netmask')
    gw = validate_exists(args, 'gateway')

    vm_ref = session.xenapi.VM.get_by_uuid(vm_uuid)

    def add_config(key, value):
        session.xenapi.VM.add_to_xenstore_data(
            vm_ref, "vm-data/control/%s/%s" % (iface, key), value)

    add_config('ip', ip)
    add_config('netmask', netmask)
    add_config('gateway', gw)

    return 'OK'


def handle_ipv6_static_conf(session, vm_uuid, iface, args):
    raise Exception("IPv6 support has not been implemented for this plugin")
    return None


@log_exceptions
def droid_set_static_conf(session, args):
    """Set static network configuration for droid VM"""
    vm_uuid = validate_exists(args, 'vm_uuid')
    iface = validate_exists(args, 'iface')
    protocol = validate_exists(args, 'protocol').lower()

    if protocol not in ["ipv4", "ipv6"]:
        raise Exception("Currently, static addressing is only supported for ipv4 or ivp6. (%s)" %
                        protocol)

    if protocol == "ipv4":
        return json_dumps(handle_ipv4_static_conf(session, vm_uuid, iface, args))
    elif protocol == "ipv6":
        return json_dumps(handle_ipv6_static_conf(session, vm_uuid, iface, args))
    else:
        raise Exception("Unexpected error ('%s')" % protocol)


@log_exceptions
def droid_template_import(session, args):
    """Import a xva using fully specified location"""
    # Need to encode/decode URI as it has unsafe characters for transmission.

    sr_uuid = validate_exists(args, 'sr_uuid')
    vpx_dlvm_file = validate_exists(args, 'vpx_dlvm_file')
    filename = "%s/%s" % (INSTALL_DIR, vpx_dlvm_file)
    call = [XE, 'vm-import', 'filename=%s' % filename, 'sr-uuid=%s' % sr_uuid]
    return json_dumps(make_local_call(call)["stdout"])


def process_running(process_name):
    process_list = make_local_call([PS, 'aux'])["stdout"].split('\n')
    for process in process_list:
        if process_name in process:
            log.debug("Process Found: %s" % process)
            return True
    return False


def kill_processes(process_name):
    process_list = make_local_call([PGREP, process_name])["stdout"].split('\n')
    log.debug("Process List: %s" % process_list)

    pattern = "\d+"
    regex = re.compile(pattern)

    for process in process_list:
        if regex.match(process):
            make_local_call([KILL, '-9', process])


def mark_local_pif_for_cleanup(session, device):
    # Undo any transformations between bridges/devices that may
    # have taken place already
    if 'xenbr' in device:
        device = device.replace('xenbr', 'eth')

    this_host_uuid = get_from_xensource_inventory('INSTALLATION_UUID')

    host_ref = session.xenapi.host.get_by_uuid(this_host_uuid)
    pifs = session.xenapi.host.get_PIFs(host_ref)

    for pif in pifs:
        pif_device = session.xenapi.PIF.get_device(pif)
        if pif_device == device:
            oc = session.xenapi.PIF.get_other_config(pif)
            oc[FOR_CLEANUP] = 'true'
            session.xenapi.PIF.set_other_config(pif, oc)
            return True

    raise Exception("Error: unable to find PIF for '%s' in '%s'" %
                    (device, pifs))


def run_dhclient(device):
    """Run dhclient on a specified interface. If a process already
    exists, then also take care of killing that process and starting
    dhclient up on the specified device again."""

    cmd = [DHCLIENT, "-q", "-lf",
           "/var/lib/dhclient/dhclient-%s.leases" % device,
           "-pf", "/var/run/dhclient-%s.pid" % device, device]

    cmd_str = " ".join(cmd[1:])

    call = [PS, 'aux']
    processes = make_local_call(call)["stdout"].split('\n')

    for process in processes:
        if cmd_str in process:
            log.debug(process)
            arr = process.split()
            pid = arr[1]
            make_local_call([KILL, '-9', pid])
            time.sleep(3)  # Give some time to ensure process kill

    res = make_local_call(cmd)["stdout"]

    return res


def _configure_local_device_ip(session, device, ip_addr, ip_netmask, mode):
    log.debug("Configure local device IP: (%s) (%s) (%s) (%s)" % (device,
                                                                  ip_addr,
                                                                  ip_netmask,
                                                                  mode))
    # Mark the PIF as needing cleaning up
    mark_local_pif_for_cleanup(session, device)

    if mode.lower() == "dhcp":
        # DHCP Case
        run_dhclient(device)

    else:
        # Static Case
        call = [IFCONFIG, device, ip_addr, 'netmask', ip_netmask]
        make_local_call(call)

    dev = _get_local_device(device)

    if not dev.ip:
        log.error("Settings Device: %s, IP: %s, Mask: %s" % (device,
                                                             dev.ip,
                                                             dev.mask))
        raise Exception("Error: failed to set IP for '%s'" % device)

    return dev


def _get_local_device_bridge(session, device):
    """
    Find bridge name of network from given device name.
    """

    log.debug("Searching for bridge name of device %s" % device)
    host = session.xenapi.session.get_this_host(session.handle)
    for pif in session.xenapi.host.get_PIFs(host):
        # skip sriov logical pif
        if has_sriov_feature(session) and not \
                session.xenapi.PIF.get_physical(pif) and \
                session.xenapi.PIF.get_sriov_logical_PIF_of(pif):
            continue

        if device == session.xenapi.PIF.get_device(pif):
            network = session.xenapi.PIF.get_network(pif)
            log.debug("Found matching bridge on PIF %s of network %s." %
                      (pif, network))
            return session.xenapi.network.get_bridge(network)

    for network in session.xenapi.network.get_all():
        if device == session.xenapi.network.get_bridge(network):
            log.debug("%s is a bridge." % device)
            return device

    log.debug("XAPI does not know bridge of given device %s." % device)

    if device.startswith('eth'):
        devname = device.replace('eth', 'xenbr')
        log.debug("Try using %s instead." % devname)
        return devname

    log.debug("Try using device name %s." % device)

    return device


@log_exceptions
def get_local_device_info(session, args):
    device = validate_exists(args, 'device')
    devname = _get_local_device_bridge(session, device)

    log.debug("get_local_device_info for %s" % devname)
    dev = _get_local_device(devname)
    return json_dumps(dev.to_rec())


@log_exceptions
def get_local_device_ip(session, args):
    device = validate_exists(args, 'device')
    devname = _get_local_device_bridge(session, device)

    log.debug("get_local_device_ip for: %s" % devname)
    dev = _get_local_device(devname)
    log.debug("_get_local_device %s = %s" % (dev.device, dev.ip))
    if not dev.ip:
        raise Exception("Error: could not obtain an IP for %s" % device)
    return json_dumps(dev.ip)


def _get_local_device(device_name):
    """Use ifconfig to get the IP address of a specified interface
    If one doesn't exist, return None"""

    log.debug("retracting device information of %s" % device_name)
    call = [IFCONFIG, device_name]
    data = make_local_call(call)["stdout"]

    log.debug("Retrieved: %s" % data)

    ip_pattern = "(\d{1,3})\.(\d{1,3})\.(\d{1,3})\.(\d{1,3})"
    inet_match = re.search("(inet addr:|inet )(?P<ip>%s)" % ip_pattern, data)
    mask_match = re.search("(Mask:|netmask )(?P<mask>%s)" % ip_pattern, data)
    #bcast_match = re.search("(Bcast:|broadcast )(?P<broadcast>%s)" % ip_pattern, data)

    mac_pattern = "(HWaddr|ether) (?P<mac>([0-9a-fA-F]{2}\:){5}([0-9a-fA-F]{2}))"
    mac_match = re.search(mac_pattern, data)

    rec = {"device": device_name,
           "ip": None,
           "mask": None,
           "mac": None,
           }

    if inet_match:
        rec["ip"] = inet_match.group("ip")
    else:
        log.debug("Did not find ip for '%s'" % device_name)

    if mask_match:
        rec["mask"] = mask_match.group("mask")
    else:
        log.debug("Did not find netmask for '%s'" % device_name)

    if mac_match:
        rec["mac"] = mac_match.group("mac")
    else:
        log.error("Did not find MAC for '%s'" % device_name)

    iface = Iface(rec)
    log.debug("Got Iface: %s" % iface.to_rec())

    return iface


def configure_local_device_ip(session, device_name, ip_addr, ip_netmask, mode):
    """For the local Dom0, configure a bridge for the particular 
    device name in order to run a service bound to that interface"""

    log.debug("configure_local_device_ip (%s) (%s) (%s) (%s)" % (device_name,
                                                                 ip_addr,
                                                                 ip_netmask,
                                                                 mode))

    device = _get_local_device_bridge(session, device_name.lower())
    dev = _get_local_device(device)

    if not dev.ip or not dev.mask:
        dev = _configure_local_device_ip(session,
                                         device,
                                         ip_addr,
                                         ip_netmask,
                                         mode)

    return dev


@log_exceptions
def flush_local_device(session, args):
    """flush IP of local device"""
    device = validate_exists(args, 'device')
    log.debug("Flushing IP of device: %s" % (device))

    bridge = _get_local_device_bridge(session, device)
    make_local_call(['ip', 'addr', 'flush', 'dev', bridge])

    return json_dumps("OK")


@log_exceptions
def configure_local_device(session, args):
    """Configure a local ethernet interface"""
    device = validate_exists(args, 'device')
    mode = validate_exists(args, 'mode')
    log.debug("configure_local_device (%s) (%s)" % (device, mode))

    ip_addr = None
    ip_netmask = None

    if mode == "static":
        ip_addr = validate_exists(args, 'ip_addr')
        ip_netmask = validate_exists(args, 'ip_netmask')
    else:
        if mode.lower() != "dhcp":
            raise Exception("Error: invalid 'mode' '%s'" % mode)

    dev = configure_local_device_ip(session, device, ip_addr, ip_netmask, mode)
    return json_dumps(dev.to_rec())


@log_exceptions
def start_iperf_server(session, args):
    """Start up iPerf in sever mode. This command will block - due to how iperf returns
    from the command line issued. It should be run as an Async tasks by XAPI."""

    ip = validate_exists(args, 'ip')

    kill_processes('iperf')

    # Check for iperfs existence
    if not process_running(IPERF):
        log.debug("Iperf is not running - start process")
        # Disable iptables
        call = ['service', 'iptables', 'stop']
        make_local_call(call)

        # Start iperf - need to ensure we don't block
        call = ['nohup', IPERF, '-s', '-B', ip, '>/dev/null', '&']
        log.debug("About to start iperf server (%s)" % call)
        subprocess.Popen(call, stdout=subprocess.PIPE,
                         stderr=subprocess.PIPE,
                         close_fds=True, bufsize=4096)

        log.debug("Call executed")

        max_attempts = 10
        attempts = 0
        # Ensure that the iperf server has actually been started
        while not process_running(IPERF) or attempts > max_attempts:
            log.debug("%d: Iperf server not yet started...waiting" % attempts)
            time.sleep(1)
            attempts = attempts + 1

        if attempts == max_attempts:
            log.debug("Failed to start the iperf server!")
            return json_dumps("Error")

        log.debug("Iperf server started")
        return json_dumps("OK")
    else:
        raise Exception("ERR: did not kill all iperf processes")

############# Utility function #####################


@log_exceptions
def get_xcp_version(session):
    """Return the XCP version (using the master host)"""
    pool = session.xenapi.pool.get_all()[0]
    master_ref = session.xenapi.pool.get_master(pool)
    software = session.xenapi.host.get_software_version(master_ref)
    return software['platform_version']


@log_exceptions
def get_kernel_version(session, args):
    """Check kernel version using uname."""
    return json_dumps(make_local_call(['uname', '-r'])["stdout"])


@log_exceptions
def get_ack_version(session, args):
    """Check ACK version using `rpm -qi`"""
    call = ['rpm', '-qi', 'auto-cert-kit']
    out = make_local_call(call)
    if out['returncode']:
        return json_dumps(None)
    ver = [i.split(":")[-1]
           for i in out['stdout'].split("\n") if i.startswith('Version')]
    if ver and len(ver) == 1:
        return json_dumps(ver[0].strip())
    raise Exception("Unable to parse ack version")


@log_exceptions
def has_sriov_feature(session):
    return get_xcp_version(session) >= XCP_MIN_VER_WITH_SRIOV


@log_exceptions
def get_dmidecode_output(session, args):
    """Returns output of dmidecode call"""
    return json_dumps(make_local_call(['dmidecode'])["stdout"])


@log_exceptions
def get_system_info_hwinfo(session, args):
    """Returns device dict reported by hwinfo"""
    host = inspector.Host()
    options = ['bios', 'nic', 'storage', 'gpu', 'cpu']
    return inspector.export_system_info(host, options)


@log_exceptions
def get_system_info_tabular(session, args):
    """Get Hardware information reported by hwinfo in tabular form"""
    host = inspector.Host()
    options = ['bios', 'nic', 'storage', 'gpu', 'cpu']
    return json_dumps(inspector.system_info(host, options))


#####################################################

if __name__ == '__main__':
    XenAPIPlugin.dispatch({'get_hw_offloads': get_hw_offloads,
                           'get_hw_offloads_from_core': get_hw_offloads_from_core,
                           'set_hw_offload': set_hw_offload,
                           'iperf_test': iperf_test,
                           'lmbench_test': lmbench_test,
                           'deploy_iperf': deploy_iperf,
                           'deploy_lmbench': deploy_lmbench,
                           'deploy_iozone': deploy_iozone,
                           'deploy_bonnie': deploy_bonnie,
                           'deploy_tcpdump': deploy_tcpdump,
                           'start_tcpdump_server': start_tcpdump_server,
                           'kill_tcpdump_server': kill_tcpdump_server,
                           'get_tcpdump_data': get_tcpdump_data,
                           'get_network_backend': get_network_backend,
                           'set_network_backend_pool': set_network_backend_pool,
                           'set_network_backend': set_network_backend,
                           'droid_set_static_conf': droid_set_static_conf,
                           'droid_template_import': droid_template_import,
                           'retrieve_lmbench_logs': retrieve_lmbench_logs,
                           'retrieve_iozone_logs': retrieve_iozone_logs,
                           'retrieve_bonnie_logs': retrieve_bonnie_logs,
                           'get_network_devices': get_network_devices,
                           'get_local_storage_devices': get_local_storage_devices,
                           'get_system_info_hwinfo': get_system_info_hwinfo,
                           'get_system_info_tabular': get_system_info_tabular,
                           'get_iface_stats': get_iface_stats,
                           'get_host_routes': get_host_routes,
                           'set_nic_device_status': set_nic_device_status,
                           'get_local_device_linkstate': get_local_device_linkstate,
                           'create_output_package': create_output_package,
                           'start_iperf_server': start_iperf_server,
                           'add_route': add_route,
                           'remove_route': remove_route,
                           'reset_arp': reset_arp,
                           'flush_local_device': flush_local_device,
                           'configure_local_device': configure_local_device,
                           'get_local_device_ip': get_local_device_ip,
                           'get_local_device_info': get_local_device_info,
                           'inject_ssh_key': inject_ssh_key,
                           'get_kernel_version': get_kernel_version,
                           'get_dmidecode_output': get_dmidecode_output,
                           'get_ack_version': get_ack_version,
                           'run_ack_logrotate': run_ack_logrotate,
                           'retrieve_crashdumps': retrieve_crashdumps,
                           'force_crash_host': force_crash_host,
                           'deploy_vf_driver': deploy_vf_driver,
                           'shell_run': shell_run
                           })